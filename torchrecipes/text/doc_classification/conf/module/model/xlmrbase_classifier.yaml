_target_: torchtext.models.RobertaModelBundle.build_model
encoder_conf:
  _target_: torchtext.models.RobertaEncoderConf
  vocab_size: 250002
  embedding_dim: 768
  ffn_dimension: 3072
  padding_idx: 1
  max_seq_len: 514
  num_attention_heads:  12
  num_encoder_layers: 12
  dropout: 0.1
  scaling: null
  normalize_before: False
head:
  _target_: torchtext.models.RobertaClassificationHead
  num_classes: 2
  input_dim: 768
  inner_dim: 1024
  dropout: 0
freeze_encoder: False
checkpoint: https://download.pytorch.org/models/text/xlmr.base.encoder.pt
